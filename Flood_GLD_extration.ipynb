{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This code only extracts the 2018 flooded and jrc_perm_water raster data layers, \n",
    "as well as the vector data of image properties, from the Global Flood Database v1 (2000-2018) product. \n",
    "It does not alter the original data’s spatial resolution. For subsequent analysis, see Dataprepare-Disasters.R.\n",
    "\n",
    "Script Functionality:\n",
    "The script reads a local shapefile for the region boundary, filters flood event data, applies conditions to isolate specific flood areas, and exports the processed image to Google Drive.\n",
    "\n",
    "Input Parameters:\n",
    "Shapefile Path: File path for the shapefile containing regional boundaries.\n",
    "Google Earth Engine Project Name: Project identifier required for Earth Engine initialization.\n",
    "\n",
    "Dependencies:\n",
    "Earth Engine API: pip install earthengine-api\n",
    "Geopandas: pip install geopandas (for reading shapefiles)\n",
    "\n",
    "Version Information:\n",
    "Version: v1.0\n",
    "Change Log: October 30, 2024.\n",
    "\"\"\"\n",
    "import ee\n",
    "import geopandas as gpd\n",
    "\n",
    "# Initialize Google Earth Engine\n",
    "ee.Authenticate()  # Authenticate Earth Engine (requires Google account login)\n",
    "ee.Initialize(project=\"lizeshuo\")  # Initialize Earth Engine with specified project ID\n",
    "\n",
    "# Read the local shapefile\n",
    "# Use geopandas to read the shapefile and convert it to GeoJSON format\n",
    "gdf = gpd.read_file(\"E:/ghana/Province/1/1/Ghana_Expanded_Boundaries.shp\")\n",
    "geometry = gdf.geometry[0]  # Assuming there is only one region in the shapefile\n",
    "region = ee.Geometry.Polygon(geometry.__geo_interface__['coordinates'])  # Convert to GEE-compatible format\n",
    "\n",
    "# Load flood dataset\n",
    "dataset = ee.ImageCollection(\"GLOBAL_FLOOD_DB/MODIS_EVENTS/V1\")\n",
    "\n",
    "# Filter dataset to only include data from 2018\n",
    "flood_2018 = dataset.filterDate(\"2018-01-01\", \"2018-12-31\")\n",
    "\n",
    "# Select the 'flooded' and 'jrc_perm_water' bands\n",
    "flooded_band = flood_2018.select(\"flooded\").sum()  # Sum all 'flooded' pixels over the year\n",
    "jrc_perm_water_band = flood_2018.select(\"jrc_perm_water\").sum()  # Sum permanent water pixels over the year\n",
    "\n",
    "# Define condition to identify pixels that are flooded but not permanently water-covered\n",
    "condition = jrc_perm_water_band.eq(0).And(flooded_band.eq(1))\n",
    "\n",
    "# Export the filtered image to Google Drive\n",
    "export_filtered_image = ee.batch.Export.image.toDrive(\n",
    "    image=condition,\n",
    "    description='Flood_GLD_flooded_jrc_perm_water_2018',  # Task name for the export\n",
    "    scale=30,  # Spatial resolution in meters\n",
    "    region=region,  # Area of interest from shapefile\n",
    "    maxPixels=1e10  # Set maximum pixel count for export\n",
    ")\n",
    "\n",
    "export_filtered_image.start()  # Begin the export task\n",
    "# End of the script\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code only extracts the 2018 flooded and jrc_perm_water raster data layers, \n",
    "as well as the vector data of image properties, from the Global Flood Database v1 (2000-2018) product. \n",
    "It does not alter the original data’s spatial resolution. For subsequent analysis, see Dataprepare-Disasters.R.\n",
    "\n",
    "Script Functionality:\n",
    "The script reads a local shapefile for the region boundary, filters the flood dataset by date, extracts image properties from each flood event, and exports the properties as a CSV file to Google Drive for analysis.\n",
    "\n",
    "Input Parameters:\n",
    "Shapefile: A local shapefile containing the boundary of the target region.\n",
    "Flood Event Data: MODIS Global Flood Database (Earth Engine) for analyzing flood events within 2018.\n",
    "\n",
    "Dependencies:\n",
    "Earth Engine Python API: For data access and processing. Install with pip install earthengine-api\n",
    "Geopandas: To read shapefiles and convert them to GeoJSON format compatible with Earth Engine. Install with pip install geopandas\n",
    "\n",
    "Version Information:\n",
    "Version: v1.0\n",
    "Change Log: October 30, 2024\n",
    "\"\"\"\n",
    "import ee\n",
    "import geopandas as gpd\n",
    "\n",
    "# Initialize Earth Engine\n",
    "ee.Authenticate()  # Authenticate Earth Engine (requires Google account login)\n",
    "ee.Initialize(project=\"lizeshuo\")  # Initialize Earth Engine with specified project ID\n",
    "\n",
    "# Define the ImageCollection\n",
    "collection = ee.ImageCollection(\"GLOBAL_FLOOD_DB/MODIS_EVENTS/V1\")\n",
    "\n",
    "# Read the local shapefile\n",
    "# Use geopandas to read the shapefile and convert it to GeoJSON format\n",
    "gdf = gpd.read_file(\"E:/ghana/Province/1/1/Ghana_Expanded_Boundaries.shp\")\n",
    "geometry = gdf.geometry[0]  # Assuming there is only one region in the shapefile\n",
    "region = ee.Geometry.Polygon(geometry.__geo_interface__['coordinates'])  # Convert to GEE-compatible format\n",
    "\n",
    "# Load the flood dataset\n",
    "collection = ee.ImageCollection(\"GLOBAL_FLOOD_DB/MODIS_EVENTS/V1\")\n",
    "\n",
    "# Filter the dataset to include only data from 2018\n",
    "collection = collection.filterDate(\"2018-01-01\", \"2018-12-31\")\n",
    "\n",
    "# Define a function to extract properties of each image\n",
    "def get_image_properties(image):\n",
    "    return ee.Feature(None, image.toDictionary(image.propertyNames()))  # Convert image properties to Feature\n",
    "\n",
    "# Map the function over the collection and convert all image properties to a FeatureCollection\n",
    "properties_collection = ee.FeatureCollection(collection.map(get_image_properties))\n",
    "\n",
    "# Set up an export task to Google Drive\n",
    "task = ee.batch.Export.table.toDrive(\n",
    "    collection=properties_collection,\n",
    "    description='Flood_GLD_image_properties_2018',  # Task description for export\n",
    "    fileFormat='CSV'  # Export file format\n",
    ")\n",
    "\n",
    "# Start the export task\n",
    "task.start()\n",
    "\n",
    "print('Export task has started. Check Google Drive for the file upon completion.')\n",
    "# End of the script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转换完成，Shapefile已保存为 E:/ghana/flood/shp/flood_image_properties.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11693\\AppData\\Local\\Temp\\ipykernel_28996\\2322547566.py:42: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  gdf.to_file(shapefile_path, driver='ESRI Shapefile')\n",
      "d:\\anaconda3\\envs\\gee\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'composite_type' to 'composite_'\n",
      "  ogr_write(\n",
      "d:\\anaconda3\\envs\\gee\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'dfo_country' to 'dfo_countr'\n",
      "  ogr_write(\n",
      "d:\\anaconda3\\envs\\gee\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'dfo_displaced' to 'dfo_displa'\n",
      "  ogr_write(\n",
      "d:\\anaconda3\\envs\\gee\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'dfo_main_cause' to 'dfo_main_c'\n",
      "  ogr_write(\n",
      "d:\\anaconda3\\envs\\gee\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'dfo_other_country' to 'dfo_other_'\n",
      "  ogr_write(\n",
      "d:\\anaconda3\\envs\\gee\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'dfo_severity' to 'dfo_severi'\n",
      "  ogr_write(\n",
      "d:\\anaconda3\\envs\\gee\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'dfo_validation_type' to 'dfo_valida'\n",
      "  ogr_write(\n",
      "d:\\anaconda3\\envs\\gee\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'gfd_country_code' to 'gfd_countr'\n",
      "  ogr_write(\n",
      "d:\\anaconda3\\envs\\gee\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'gfd_country_name' to 'gfd_coun_1'\n",
      "  ogr_write(\n",
      "d:\\anaconda3\\envs\\gee\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'glide_index' to 'glide_inde'\n",
      "  ogr_write(\n",
      "d:\\anaconda3\\envs\\gee\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'slope_threshold' to 'slope_thre'\n",
      "  ogr_write(\n",
      "d:\\anaconda3\\envs\\gee\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'thresh_b1b2' to 'thresh_b1b'\n",
      "  ogr_write(\n",
      "d:\\anaconda3\\envs\\gee\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'thresh_type' to 'thresh_typ'\n",
      "  ogr_write(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "This code only extracts the 2018 flooded and jrc_perm_water raster data layers, \n",
    "as well as the vector data of image properties, from the Global Flood Database v1 (2000-2018) product. \n",
    "It does not alter the original data’s spatial resolution. For subsequent analysis, see Dataprepare-Disasters.R.\n",
    "\n",
    "Script Functionality:\n",
    "This script processes flood image property data from a CSV file, preparing it for spatial analysis by converting it to a Shapefile format. \n",
    "The script performs essential tasks, such as renaming columns for compatibility, truncating long text fields, creating point geometries from centroid coordinates, and setting the coordinate reference system to WGS84 (EPSG:4326).\n",
    "\n",
    "Input Parameters:\n",
    "A local CSV file with flood event metadata, including centroid coordinates (cent_x and cent_y) for each event.\n",
    "\n",
    "Dependencies:\n",
    "Pandas: For loading and manipulating CSV data. Install via pip install pandas\n",
    "Geopandas: For handling spatial data and exporting it as a Shapefile. Install via pip install geopandas\n",
    "Shapely: For creating point geometries. Installed automatically with Geopandas\n",
    "\n",
    "Version Information:\n",
    "Version: v1.0\n",
    "Change Log: October 30, 2024\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Read the CSV file\n",
    "file_path = 'E:/ghana/flood/flood_image_properties.csv'\n",
    "data = pd.read_csv(file_path)  # Load data from CSV into a DataFrame\n",
    "\n",
    "# Rename columns to ensure field names are under 10 characters\n",
    "data.rename(columns={\n",
    "    'system:index': 'sys_index',\n",
    "    'dfo_centroid_x': 'cent_x',\n",
    "    'dfo_centroid_y': 'cent_y',\n",
    "    'system:asset_size': 'asset_size',\n",
    "    'system:footprint': 'footprint',\n",
    "    'system:id': 'sys_id',\n",
    "    'system:time_end': 'time_end',\n",
    "    'system:time_start': 'time_start',\n",
    "    'system:version': 'version',\n",
    "    'threshold_b1b2': 'thresh_b1b2',\n",
    "    'threshold_b7': 'thresh_b7',\n",
    "    'threshold_type': 'thresh_type'\n",
    "}, inplace=True)\n",
    "\n",
    "# Truncate the `footprint` text field to ensure it does not exceed 254 characters\n",
    "data['footprint'] = data['footprint'].astype(str).str.slice(0, 254)\n",
    "\n",
    "# Create geometry points using `cent_x` and `cent_y` coordinates\n",
    "data['geometry'] = data.apply(lambda row: Point(row['cent_x'], row['cent_y']), axis=1)\n",
    "\n",
    "# Drop unnecessary fields, including `.geo` and timestamp fields\n",
    "data.drop(columns=['.geo', 'time_end', 'time_start'], inplace=True)\n",
    "\n",
    "# Convert the DataFrame to a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(data, geometry='geometry')\n",
    "\n",
    "# Set the coordinate reference system (WGS84 - EPSG:4326)\n",
    "gdf.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "# Save the GeoDataFrame as a Shapefile\n",
    "shapefile_path = 'F:/[2024.07]Ghana/Processed Data/Disasters/Extraction/Flood_GLD_image_properties_2018.shp'\n",
    "gdf.to_file(shapefile_path, driver='ESRI Shapefile')\n",
    "\n",
    "print(f\"Conversion complete. Shapefile saved at {shapefile_path}\")\n",
    "# End of the script"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
